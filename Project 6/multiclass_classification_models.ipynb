{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "1. **Build a Multiclass Classification Model with Linear Decision Boundaries:**\n",
    "    - Import necessary libraries.\n",
    "    - Import the dataset from UCIML repository, view it, check its shape, check for missing values and total classes in $y$.\n",
    "    - Define functions for splitting the dataset and standardizing it using Scikit-Learn.\n",
    "    - Split and standardize the dataset.\n",
    "    - Train linear and non-linear/polynomial multinomial logistic regression models using Scikit-Learn.\n",
    "    - Evaluate each model on training, cross-validation, and testing datasets.\n",
    "    - Determine the optimal model, which was linear multinomial logistic regression.\n",
    "    - Build a custom model based on the resulting optimal model.\n",
    "    - Train and evaluate the custom model and compare results with the Scikit-Learn model.\n",
    "\n",
    "2. **Build a Multiclass Classification Model with Non-linear Decision Boundaries:**\n",
    "    - Get the dataset from the same source as before, view it, check its shape, check for missing values and total classes in $y$.\n",
    "    - Split and standardize the dataset.\n",
    "    - Train and evaulate linear and non-linear/polynomial multinomial logistic regression models using Scikit-Learn.\n",
    "    - Determine the optimal model, which was a polynomial degree **2** multinomial logistic regression model.\n",
    "    - Based on the resulting optimal model, build a custom model.\n",
    "    - Train and evaluate the custom model and compare results with the Scikit-Learn model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiclass Classification Model with Linear Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This project uses data from the [`UCI Machine Learning Repository`](https://archive.ics.uci.edu/dataset/107/waveform+database+generator+version+1). The dataset is licensed under a [`Creative Commons Attribution 4.0 International (CC BY 4.0) license`](https://creativecommons.org/licenses/by/4.0/legalcode). The features (X) and target (y) variables were converted into numpy arrays, for building a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "waveform_database_generator_version_1 = fetch_ucirepo(id=107) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = waveform_database_generator_version_1.data.features \n",
    "y = waveform_database_generator_version_1.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute12</th>\n",
       "      <th>Attribute13</th>\n",
       "      <th>Attribute14</th>\n",
       "      <th>Attribute15</th>\n",
       "      <th>Attribute16</th>\n",
       "      <th>Attribute17</th>\n",
       "      <th>Attribute18</th>\n",
       "      <th>Attribute19</th>\n",
       "      <th>Attribute20</th>\n",
       "      <th>Attribute21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.23</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>2.89</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.59</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.69</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.42</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.37</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.84</td>\n",
       "      <td>...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.53</td>\n",
       "      <td>...</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.76</td>\n",
       "      <td>...</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4.89</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.37</td>\n",
       "      <td>3.68</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.87</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.70</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.81</td>\n",
       "      <td>5.20</td>\n",
       "      <td>...</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.24</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-1.92</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.73</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.89</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.13</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.14</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.75</td>\n",
       "      <td>...</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.39</td>\n",
       "      <td>4.24</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.56</td>\n",
       "      <td>3.18</td>\n",
       "      <td>1.51</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.08</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
       "0       -1.23       -1.56       -1.75       -0.28        0.60        2.22   \n",
       "1       -0.69        2.43        0.61        2.08        2.30        3.25   \n",
       "2       -0.12       -0.94        1.29        2.59        2.42        3.55   \n",
       "3        0.86        0.29        2.19       -0.02        1.13        2.51   \n",
       "4        1.16        0.37        0.40       -0.59        2.66        1.00   \n",
       "5       -0.00        0.77        1.32        0.29       -1.28        0.84   \n",
       "6        0.87        1.07       -0.65        1.46        0.84        2.70   \n",
       "7       -0.22       -0.91       -1.18        0.35       -1.92       -1.59   \n",
       "8       -1.11       -1.14       -0.89        0.00        0.53        0.44   \n",
       "9       -0.75        1.10       -1.90        1.43        0.47        0.40   \n",
       "\n",
       "   Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute12  \\\n",
       "0        0.85        0.21       -0.20         0.89  ...         4.20   \n",
       "1        5.52        4.55        2.97         2.22  ...         1.61   \n",
       "2        4.94        3.25        1.90         2.07  ...         1.45   \n",
       "3        2.37        5.45        5.45         4.84  ...         4.05   \n",
       "4        2.69        4.06        5.34         3.53  ...         4.79   \n",
       "5        1.60        1.55        2.93         4.76  ...         4.30   \n",
       "6        3.67        2.94        3.81         5.20  ...         3.29   \n",
       "7        1.91        0.75        1.72         2.02  ...         3.91   \n",
       "8        0.24        2.15        1.64         1.75  ...         5.68   \n",
       "9        0.86        3.51        2.62         4.50  ...         6.94   \n",
       "\n",
       "   Attribute13  Attribute14  Attribute15  Attribute16  Attribute17  \\\n",
       "0         2.89         7.75         4.59         3.15         5.12   \n",
       "1         1.24         1.89         1.88        -1.34         0.83   \n",
       "2         2.50         0.12         1.41         2.78         0.64   \n",
       "3         2.58         1.40         1.24         1.41         1.07   \n",
       "4         4.30         1.84         1.73         0.21        -0.18   \n",
       "5         4.89         2.81         2.37         3.68        -0.98   \n",
       "6         4.24         2.43         0.40         1.60         0.72   \n",
       "7         2.73         4.29         4.89         2.04         1.13   \n",
       "8         3.39         4.24         3.81         4.56         3.18   \n",
       "9         0.75         3.23         1.08        -0.25         0.73   \n",
       "\n",
       "   Attribute18  Attribute19  Attribute20  Attribute21  \n",
       "0         3.32         1.20         0.24        -0.56  \n",
       "1         1.41         1.78         0.60         2.42  \n",
       "2         0.62        -0.01        -0.79        -0.12  \n",
       "3        -1.43         2.84        -1.18         1.12  \n",
       "4         0.13        -0.21        -0.80        -0.68  \n",
       "5         0.69         0.91        -1.80         0.39  \n",
       "6         0.66         0.05        -0.24         0.67  \n",
       "7        -0.66        -1.33         0.41        -0.75  \n",
       "8         1.51         2.90         0.14        -0.12  \n",
       "9        -0.41        -1.50         0.46         1.47  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 10 rows of features data\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class\n",
       "0         2\n",
       "1         1\n",
       "2         0\n",
       "3         1\n",
       "4         1\n",
       "...     ...\n",
       "4995      0\n",
       "4996      1\n",
       "4997      1\n",
       "4998      0\n",
       "4999      1\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View target data\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X = (5000, 21)\n",
      "Shape of y = (5000, 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Missing values in X: \n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "\n",
      "Missing values in y: \n",
      "[False]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Total classes in y: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X and y\n",
    "print(f\"Shape of X = {X.shape}\")\n",
    "print(f\"Shape of y = {y.shape}\")\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "\n",
    "# Check for any missing values for X and y\n",
    "print(f\"\\nMissing values in X: \\n{X.isna().any().values}\")\n",
    "print(f\"\\nMissing values in y: \\n{y.isna().any().values}\")\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "\n",
    "# Check for how many classes are in y\n",
    "print(f\"\\nTotal classes in y: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a cleaned dataset with **5,000** training examples, **21** feature variables, and **1** target variable. Our goal is to build a multiclass classification model with a linear decision boundaries. To ensure that the linear decision boundaries will be suitable for this multiclass dataset, we will first use scikit-learn to build and evaluate both linear and non-linear/polynomial multiclass classification models. After identifying the optimal scikit-learn model, we will develop a custom model based on these findings and compare its results with the optimal scikit-learn model. This approach saves time by efficiently determining the best model type before building our custom models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    # Splitting the data into training (60%), cross-validation (20%), and testing (20%) sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "def standardize_dataset(X_train, X_val, X_test):\n",
    "    # Standardizing the datasets\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fitting the scaler on the training data and transforming training, validation, and testing sets\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return scaler, X_train_scaled, X_val_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3000, 21), (3000,)\n",
      "Validation set: (1000, 21), (1000,)\n",
      "Test set: (1000, 21), (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the features (X) and target (y) variables into numpy arrays\n",
    "X = X.to_numpy()\n",
    "y = y[\"class\"].to_numpy()\n",
    "\n",
    "# Splitting the dataset into training, validation, and test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(X, y)\n",
    "\n",
    "# Standardizing the feature datasets (training, validation, and test sets) to have zero mean and unit variance\n",
    "scaler, X_train_scaled, X_val_scaled, X_test_scaled = standardize_dataset(X_train, X_val, X_test)\n",
    "\n",
    "# Printing the shapes of the resulting datasets\n",
    "print(f\"Training set: {X_train_scaled.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val_scaled.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test_scaled.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 0.8727, Precision: 0.8725, Recall: 0.8727, F1-score: 0.8724\n",
      "Validation set - Accuracy: 0.8670, Precision: 0.8679, Recall: 0.8670, F1-score: 0.8668\n",
      "Test set - Accuracy: 0.8860, Precision: 0.8862, Recall: 0.8860, F1-score: 0.8857\n",
      "\n",
      "Polynomial Degree 2 Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 0.9330, Precision: 0.9329, Recall: 0.9330, F1-score: 0.9329\n",
      "Validation set - Accuracy: 0.8390, Precision: 0.8390, Recall: 0.8390, F1-score: 0.8388\n",
      "Test set - Accuracy: 0.8490, Precision: 0.8489, Recall: 0.8490, F1-score: 0.8490\n",
      "\n",
      "Polynomial Degree 3 Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
      "Validation set - Accuracy: 0.8200, Precision: 0.8199, Recall: 0.8200, F1-score: 0.8199\n",
      "Test set - Accuracy: 0.8280, Precision: 0.8283, Recall: 0.8280, F1-score: 0.8278\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def train_eval_multinomial_logistic_regression(X_train, y_train, X_val, y_val, X_test, y_test, degree=1):\n",
    "    # Initialize multinomial logistic regression model for multiclass classification (linear/polynomial)\n",
    "    model = make_pipeline(\n",
    "        PolynomialFeatures(degree=degree),\n",
    "        LogisticRegression(random_state=42, max_iter=1000, multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on training set\n",
    "    train_acc, train_prec, train_rec, train_f1 = evaluate_model(model, X_train, y_train)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_acc, val_prec, val_rec, val_f1 = evaluate_model(model, X_val, y_val)\n",
    "\n",
    "    # Evaluate on testing set\n",
    "    test_acc, test_prec, test_rec, test_f1 = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    print(\"Linear Multinomial Logistic Regression:\") if degree == 1 else \\\n",
    "    print(f\"\\nPolynomial Degree {degree} Multinomial Logistic Regression:\")\n",
    "    \n",
    "    print(f\"Training set - Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_rec:.4f}, \"\n",
    "            f\"F1-score: {train_f1:.4f}\")\n",
    "\n",
    "    print(f\"Validation set - Accuracy: {val_acc:.4f}, Precision: {val_prec:.4f}, Recall: {val_rec:.4f}, \"\n",
    "            f\"F1-score: {val_f1:.4f}\")\n",
    "    \n",
    "    print(f\"Test set - Accuracy: {test_acc:.4f}, Precision: {test_prec:.4f}, Recall: {test_rec:.4f}, \"\n",
    "            f\"F1-score: {test_f1:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    # Predict the target values using the provided model and features\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate the accuracy of the model\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    # Calculate the precision of the model\n",
    "    precision = precision_score(y, y_pred, average=\"weighted\")\n",
    "    # Calculate the recall of the model\n",
    "    recall = recall_score(y, y_pred, average=\"weighted\")\n",
    "    # Calculate the F1 score of the model\n",
    "    f1 = f1_score(y, y_pred, average=\"weighted\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "# Train and evaluate linear multinomial logistic regression model for multiclass classification\n",
    "linear_mlr_model = train_eval_multinomial_logistic_regression(\n",
    "    X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test\n",
    "    )\n",
    "\n",
    "# Train and evaluate polynomial (degree 2) multinomial logistic regression model for multiclass classification\n",
    "poly2_mlr_model = train_eval_multinomial_logistic_regression(\n",
    "    X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, degree=2\n",
    "    )\n",
    "\n",
    "# Train and evaluate polynomial (degree 3) multinomial logistic regression model for multiclass classification\n",
    "poly3_mlr_model = train_eval_multinomial_logistic_regression(\n",
    "    X_train_scaled, y_train, X_val_scaled, y_val, X_test_scaled, y_test, degree=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above evaluations, the **Linear Multinomial Logistic Regression** model shows the best balance between bias and variance, with validation and test set scores indicating better generalization: **validation accuracy** of **0.8670** and **test accuracy** of **0.8860**. The **Polynomial Degree 2** model, while achieving a high **training accuracy** of **0.9330**, performs worse on validation (**0.8390**) and test sets (**0.8490**), suggesting overfitting. The **Polynomial Degree 3** model significantly overfits, with a perfect **training accuracy** of **1.0000** but lower validation (**0.8200**) and test accuracy (**0.8280**). Hence, the **Linear Multinomial Logistic Regression** model is the optimal choice for this dataset. Now, we will build our **Custom Linear Multinomial Logistic Regression** model and compare the results with the scikit-learn optimal model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial logistic regression (softmax regression) model can be represented as:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{Y}} = \\sigma(\\mathbf{X} \\cdot \\mathbf{W} + \\mathbf{b})\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\hat{\\mathbf{Y}}$ represents the predicted probabilities matrix,\n",
    "- $\\sigma(\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^{K} e^{z_k}}$ is the softmax function that converts the output logits into probabilities,\n",
    "- $j = 1, 2, \\ldots, K$,\n",
    "- $K$ is the number of classes,\n",
    "- $\\mathbf{X}$ represents the features matrix,\n",
    "- $\\mathbf{W}$ represents the weight matrix,\n",
    "- $\\mathbf{b}$ represents the bias vector.\n",
    "\n",
    "To train the multinomial logistic regression model, we use the cross-entropy loss as the loss function:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{Cross-Entropy Loss} = -\\frac{1}{m} \\sum_{i=1}^{m} \\sum_{k=1}^{K} y_{i,k} \\log(\\hat{y}_{i,k}) \\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $m$ is the number of data points,\n",
    "- $y_{i,k}$ is the actual binary indicator (0 or 1) if the class label of the $i$-th instance is $k$,\n",
    "- $\\hat{y}_{i,k}$ is the predicted probability that the $i$-th instance belongs to class $k$.\n",
    "\n",
    "To update the parameters $\\mathbf{W}$ and $\\mathbf{b}$, we use gradient descent:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{W}_{\\text{new}} = \\mathbf{W}_{\\text{old}} - \\alpha \\times \\frac{\\partial \\text{Cross-Entropy Loss}}{\\partial \\mathbf{W}} \\tag{3}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathbf{b}_{\\text{new}} = \\mathbf{b}_{\\text{old}} - \\alpha \\times \\frac{\\partial \\text{Cross-Entropy Loss}}{\\partial \\mathbf{b}} \\tag{4}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{W}_{\\text{new}}$ and $\\mathbf{W}_{\\text{old}}$ are the updated and current weight matrices, respectively,\n",
    "- $\\mathbf{b}_{\\text{new}}$ and $\\mathbf{b}_{\\text{old}}$ are the updated and current bias vectors, respectively,\n",
    "- $\\alpha$ is the learning rate,\n",
    "- $\\frac{\\partial \\text{Cross-Entropy Loss}}{\\partial \\mathbf{W}}$ is the gradient of the Cross-Entropy Loss function with respect to the weight matrix,\n",
    "- $\\frac{\\partial \\text{Cross-Entropy Loss}}{\\partial \\mathbf{b}}$ is the gradient of the Cross-Entropy Loss function with respect to the bias vector.\n",
    "\n",
    "The gradients with respect to the weights and biases are computed as follows:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\text{Cross-Entropy Loss}}{\\partial \\mathbf{W}} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_{i,k} - {y}_{i,k}) {x}_{i,j} \\tag{5}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\text{Cross-Entropy Loss}}{\\partial \\mathbf{b}} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_{i,k} - {y}_{i,k}) \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        self.cost_history = []\n",
    "\n",
    "\n",
    "    def initialize_parameters(self, n_features, k_classes):\n",
    "        # Initialize weights as a zero matrix of shape (n_features, k_classes)\n",
    "        self.weights = np.zeros((n_features, k_classes))\n",
    "        \n",
    "        # Initialize biases as a zero vector of shape (k_classes,)\n",
    "        self.biases = np.zeros(k_classes)\n",
    "\n",
    "    \n",
    "    def softmax(self, Z):\n",
    "        # Return the softmax output\n",
    "        return np.exp(Z) / np.sum(np.exp(Z), axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    def compute_cost(self, Y_hat, Y_one_hot):\n",
    "        # Get the number of samples\n",
    "        m = Y_one_hot.shape[0]\n",
    "\n",
    "        # Small epsilon value to prevent log(0)\n",
    "        epsilon = 1e-10\n",
    "\n",
    "        # Compute the cost using cross-entropy loss function\n",
    "        cost = - (1 / m) * np.sum(Y_one_hot * np.log(Y_hat + epsilon))\n",
    "        \n",
    "        return cost \n",
    "   \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Get the shape of X\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Get the total number of unique classes in y\n",
    "        k = len(np.unique(y))\n",
    "\n",
    "        # One-hot encoding for vectorized implementation\n",
    "        Y_one_hot = np.eye(k)[y]\n",
    "        \n",
    "        # Initialize parameters weights and biases\n",
    "        self.initialize_parameters(n, k)\n",
    "\n",
    "        # Run the gradient descent loop\n",
    "        for i in range(self.num_iterations):\n",
    "            # Forward propagation\n",
    "            Z = np.matmul(X, self.weights) + self.biases\n",
    "            Y_hat = self.softmax(Z)\n",
    "\n",
    "            # Compute cost\n",
    "            cost = self.compute_cost(Y_hat, Y_one_hot)\n",
    "\n",
    "            # Print cost every 100 iterations and save cost\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Iteration {i + 1}/{self.num_iterations}: Cost {cost}\")\n",
    "                self.cost_history.append((i+1, cost))\n",
    "\n",
    "            # Compute gradients\n",
    "            dW = (1 / m) * np.matmul(X.T, (Y_hat - Y_one_hot))\n",
    "            db = (1 / m) * np.sum((Y_hat - Y_one_hot), axis=0)\n",
    "\n",
    "            # Update parameters\n",
    "            self.weights -= self.learning_rate * dW\n",
    "            self.biases -= self.learning_rate * db\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Compute the linear combination of input features and weights, plus biases\n",
    "        # Note: X can be polynomial features\n",
    "        Z = np.matmul(X, self.weights) + self.biases\n",
    "        \n",
    "        # Apply the softmax function to the linear combination\n",
    "        Y_hat = self.softmax(Z)\n",
    "        \n",
    "        # Return the index of the maximum probaility in each row of Y_hat\n",
    "        return np.argmax(Y_hat, axis=1)\n",
    "    \n",
    "\n",
    "    def evaluate_model(self, X, y):\n",
    "        # Predict the target values using the provided features\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        # Calculate the accuracy of the model\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        # Calculate the precision of the model\n",
    "        precision = precision_score(y, y_pred, average=\"weighted\")\n",
    "        # Calculate the recall of the model\n",
    "        recall = recall_score(y, y_pred, average=\"weighted\")\n",
    "        # Calculate the F1 score of the model\n",
    "        f1 = f1_score(y, y_pred, average=\"weighted\")\n",
    "\n",
    "        return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/1000: Cost 0.31142376048471093\n",
      "Iteration 200/1000: Cost 0.3102091157073313\n",
      "Iteration 300/1000: Cost 0.3100006408145589\n",
      "Iteration 400/1000: Cost 0.30995123348071446\n",
      "Iteration 500/1000: Cost 0.3099373155757351\n",
      "Iteration 600/1000: Cost 0.30993294801407006\n",
      "Iteration 700/1000: Cost 0.3099314935273836\n",
      "Iteration 800/1000: Cost 0.3099309945440475\n",
      "Iteration 900/1000: Cost 0.3099308209192659\n",
      "Iteration 1000/1000: Cost 0.30993076010325465\n"
     ]
    }
   ],
   "source": [
    "# Train custom linear multinomial logistic regression model\n",
    "custom_linear_mlr_model = MultinomialLogisticRegression(learning_rate=0.7)\n",
    "custom_linear_mlr_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Iteration=%{x}<br>Cost=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          100,
          200,
          300,
          400,
          500,
          600,
          700,
          800,
          900,
          1000
         ],
         "xaxis": "x",
         "y": [
          0.31142376048471093,
          0.3102091157073313,
          0.3100006408145589,
          0.30995123348071446,
          0.3099373155757351,
          0.30993294801407006,
          0.3099314935273836,
          0.3099309945440475,
          0.3099308209192659,
          0.30993076010325465
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Iteration vs Cost"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Cost"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert cost history into numpy arrays\n",
    "cost_hist = np.array(custom_linear_mlr_model.cost_history)\n",
    "\n",
    "# Plotly Express line chart\n",
    "fig = px.line(\n",
    "    x=cost_hist[:, 0],\n",
    "    y=cost_hist[:, 1],\n",
    "    title=\"Iteration vs Cost\",\n",
    "    labels={\"x\": \"Iteration\", \"y\": \"Cost\"}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Saved as plot_1.png in the current directory/folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the decrease in cost as the number of iterations increases, flattening out at approximately 500 iterations. This indicates the proper functioning of gradient descent in minimizing cost, leading to the convergence of the model and the attainment of optimal model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Linear Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 0.8727, Precision: 0.8725, Recall: 0.8727, F1-score: 0.8724\n",
      "Validation set - Accuracy: 0.8670, Precision: 0.8679, Recall: 0.8670, F1-score: 0.8668\n",
      "Test set - Accuracy: 0.8860, Precision: 0.8862, Recall: 0.8860, F1-score: 0.8857\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the custom linear multinomial logistic regression model\n",
    "train_acc, train_prec, train_rec, train_f1 = custom_linear_mlr_model.evaluate_model(X_train_scaled, y_train)\n",
    "val_acc, val_prec, val_rec, val_f1 = custom_linear_mlr_model.evaluate_model(X_val_scaled, y_val)\n",
    "test_acc, test_prec, test_rec, test_f1 = custom_linear_mlr_model.evaluate_model(X_test_scaled, y_test)\n",
    "\n",
    "print(\"Custom Linear Multinomial Logistic Regression:\")\n",
    "\n",
    "print(f\"Training set - Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_rec:.4f}, \"\n",
    "        f\"F1-score: {train_f1:.4f}\")\n",
    "\n",
    "print(f\"Validation set - Accuracy: {val_acc:.4f}, Precision: {val_prec:.4f}, Recall: {val_rec:.4f}, \"\n",
    "        f\"F1-score: {val_f1:.4f}\")\n",
    "\n",
    "print(f\"Test set - Accuracy: {test_acc:.4f}, Precision: {test_prec:.4f}, Recall: {test_rec:.4f}, \"\n",
    "        f\"F1-score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn Linear Multinomial Logistic Regression: <br>\n",
    "Training set - Accuracy: 0.8727, Precision: 0.8725, Recall: 0.8727, F1-score: 0.8724 <br>\n",
    "Validation set - Accuracy: 0.8670, Precision: 0.8679, Recall: 0.8670, F1-score: 0.8668 <br>\n",
    "Test set - Accuracy: 0.8860, Precision: 0.8862, Recall: 0.8860, F1-score: 0.8857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Custom and Scikit-Learn implementations of the **Linear Multinomial Lgistic Regression** model yield identical results across the training, validation, and test sets. These consistent results across both implementations affirm the reliability and correctness of the model in predicting outcomes, showcasing its effective generalization to unseen data. With the goal of building a **Multiclass Classification Model with Linear Decision Boundaries** achieved, our next step is to develop a **Multiclass Classification Model with Non-Linear Decision Boundaries**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiclass Classification Model with Non-Linear Decision Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This project uses data from the [`UCI Machine Learning Repository`](https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits). The dataset is licensed under a [`Creative Commons Attribution 4.0 International (CC BY 4.0) license`](https://creativecommons.org/licenses/by/4.0/legalcode). The features (X_) and target (y_) variables were converted into numpy arrays, for building a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X_ = optical_recognition_of_handwritten_digits.data.features \n",
    "y_ = optical_recognition_of_handwritten_digits.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute1</th>\n",
       "      <th>Attribute2</th>\n",
       "      <th>Attribute3</th>\n",
       "      <th>Attribute4</th>\n",
       "      <th>Attribute5</th>\n",
       "      <th>Attribute6</th>\n",
       "      <th>Attribute7</th>\n",
       "      <th>Attribute8</th>\n",
       "      <th>Attribute9</th>\n",
       "      <th>Attribute10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attribute55</th>\n",
       "      <th>Attribute56</th>\n",
       "      <th>Attribute57</th>\n",
       "      <th>Attribute58</th>\n",
       "      <th>Attribute59</th>\n",
       "      <th>Attribute60</th>\n",
       "      <th>Attribute61</th>\n",
       "      <th>Attribute62</th>\n",
       "      <th>Attribute63</th>\n",
       "      <th>Attribute64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
       "0           0           1           6          15          12           1   \n",
       "1           0           0          10          16           6           0   \n",
       "2           0           0           8          15          16          13   \n",
       "3           0           0           0           3          11          16   \n",
       "4           0           0           5          14           4           0   \n",
       "5           0           0          11          16          10           1   \n",
       "6           0           0           1          11          13          11   \n",
       "7           0           0           8          10           8           7   \n",
       "8           0           0          15           2          14          13   \n",
       "9           0           0           3          13          13           2   \n",
       "\n",
       "   Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute55  \\\n",
       "0           0           0           0            7  ...            0   \n",
       "1           0           0           0            7  ...            3   \n",
       "2           0           0           0            1  ...            0   \n",
       "3           0           0           0            0  ...            0   \n",
       "4           0           0           0            0  ...           12   \n",
       "5           0           0           0            4  ...            8   \n",
       "6           7           0           0            0  ...            0   \n",
       "7           2           0           0            1  ...            0   \n",
       "8           2           0           0            0  ...            0   \n",
       "9           0           0           0            6  ...           12   \n",
       "\n",
       "   Attribute56  Attribute57  Attribute58  Attribute59  Attribute60  \\\n",
       "0            0            0            0            6           14   \n",
       "1            0            0            0           10           16   \n",
       "2            0            0            0            9           14   \n",
       "3            0            0            0            0            1   \n",
       "4            0            0            0            4           12   \n",
       "5            3            0            0           10           16   \n",
       "6            0            0            0            1           13   \n",
       "7            0            0            0            4           13   \n",
       "8            0            0            0           10           12   \n",
       "9            0            0            0            3           15   \n",
       "\n",
       "   Attribute61  Attribute62  Attribute63  Attribute64  \n",
       "0            7            1            0            0  \n",
       "1           15            3            0            0  \n",
       "2            0            0            0            0  \n",
       "3           15            2            0            0  \n",
       "4           14            7            0            0  \n",
       "5           16           16           16            6  \n",
       "6            5            0            0            0  \n",
       "7            8            0            0            0  \n",
       "8            5            0            0            0  \n",
       "9           11            6            0            0  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first 10 rows of features data\n",
    "X_.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5615</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5616</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5617</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5620 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class\n",
       "0         0\n",
       "1         0\n",
       "2         7\n",
       "3         4\n",
       "4         6\n",
       "...     ...\n",
       "5615      9\n",
       "5616      0\n",
       "5617      8\n",
       "5618      9\n",
       "5619      8\n",
       "\n",
       "[5620 rows x 1 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View target data\n",
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_ = (5620, 64)\n",
      "Shape of y_ = (5620, 1)\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Missing values in X_: \n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False]\n",
      "\n",
      "Missing values in y_: \n",
      "[False]\n",
      "\n",
      "---------------------------\n",
      "\n",
      "Total classes in y_: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of X_ and y_\n",
    "print(f\"Shape of X_ = {X_.shape}\")\n",
    "print(f\"Shape of y_ = {y_.shape}\")\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "\n",
    "# Check for any missing values for X_ and y_\n",
    "print(f\"\\nMissing values in X_: \\n{X_.isna().any().values}\")\n",
    "print(f\"\\nMissing values in y_: \\n{y_.isna().any().values}\")\n",
    "\n",
    "print(\"\\n---------------------------\")\n",
    "\n",
    "# Check for how many classes are in y_\n",
    "print(f\"\\nTotal classes in y_: {np.unique(y_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a cleaned dataset with **5,620** training examples, **64** feature variables, and **1** target variable. Our goal is to build a multiclass classification model with a non-linear decision boundaries. To ensure that the non-linear decision boundaries will be suitable for this multiclass dataset, we will use the same approach as we did with our previous goal of building a multiclass classification model with a linear decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3372, 64), (3372,)\n",
      "Validation set: (1124, 64), (1124,)\n",
      "Test set: (1124, 64), (1124,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the features (X_) and target (y_) variables into numpy arrays\n",
    "X_ = X_.to_numpy()\n",
    "y_ = y_[\"class\"].to_numpy()\n",
    "\n",
    "# Splitting the dataset into training, validation, and test sets\n",
    "X_train_, y_train_, X_val_, y_val_, X_test_, y_test_ = split_dataset(X_, y_)\n",
    "\n",
    "# Standardizing the feature datasets (training, validation, and test sets) to have zero mean and unit variance\n",
    "scaler_, X_train_scaled_, X_val_scaled_, X_test_scaled_ = standardize_dataset(X_train_, X_val_, X_test_)\n",
    "\n",
    "# Printing the shapes of the resulting datasets\n",
    "print(f\"Training set: {X_train_scaled_.shape}, {y_train_.shape}\")\n",
    "print(f\"Validation set: {X_val_scaled_.shape}, {y_val_.shape}\")\n",
    "print(f\"Test set: {X_test_scaled_.shape}, {y_test_.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 0.9926, Precision: 0.9926, Recall: 0.9926, F1-score: 0.9926\n",
      "Validation set - Accuracy: 0.9724, Precision: 0.9728, Recall: 0.9724, F1-score: 0.9725\n",
      "Test set - Accuracy: 0.9680, Precision: 0.9683, Recall: 0.9680, F1-score: 0.9680\n",
      "\n",
      "Polynomial Degree 2 Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
      "Validation set - Accuracy: 0.9858, Precision: 0.9861, Recall: 0.9858, F1-score: 0.9858\n",
      "Test set - Accuracy: 0.9858, Precision: 0.9858, Recall: 0.9858, F1-score: 0.9858\n",
      "\n",
      "Polynomial Degree 3 Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
      "Validation set - Accuracy: 0.9840, Precision: 0.9843, Recall: 0.9840, F1-score: 0.9840\n",
      "Test set - Accuracy: 0.9911, Precision: 0.9912, Recall: 0.9911, F1-score: 0.9911\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate linear multinomial logistic regression model for multiclass classification\n",
    "linear_mlr_model_ = train_eval_multinomial_logistic_regression(\n",
    "    X_train_scaled_, y_train_, X_val_scaled_, y_val_, X_test_scaled_, y_test_\n",
    "    )\n",
    "\n",
    "# Train and evaluate polynomial (degree 2) multinomial logistic regression model for multiclass classification\n",
    "poly2_mlr_model_ = train_eval_multinomial_logistic_regression(\n",
    "    X_train_scaled_, y_train_, X_val_scaled_, y_val_, X_test_scaled_, y_test_, degree=2\n",
    "    )\n",
    "\n",
    "# Train and evaluate polynomial (degree 3) multinomial logistic regression model for multiclass classification\n",
    "poly3_mlr_model_ = train_eval_multinomial_logistic_regression(\n",
    "    X_train_scaled_, y_train_, X_val_scaled_, y_val_, X_test_scaled_, y_test_, degree=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison of multinomial logistic regression models reveals that the **Linear Multinomial Logistic Regression** model shows good performance with a training accuracy of **0.9926**, but slightly lower than the polynomial models. The **Polynomial Degree 2 Multinomial Logistic Regression** model achieves perfect performance on the training set (**accuracy: 1.0000**) and maintains high performance on the validation (**accuracy: 0.9858**) and test sets (**accuracy: 0.9858**). The **Polynomial Degree 3** model also performs excellently, showing perfect scores on the training set and a slightly higher test accuracy (**0.9911**) than the degree **2** model. Despite the marginally better test performance of the degree **3** model, the **Polynomial Degree 2** model is chosen as optimal due to its balanced performance across training, validation, and test sets. An attempt to fit a polynomial degree **4** model resulted in a **MemoryError**, indicating the system couldn't allocate **20.5 GiB** of memory required for an array with shape **(3372, 814385)** due to the current system's **4GB RAM**. While a more powerful PC with significantly more RAM could prevent this specific memory error, high-degree polynomial models often lead to impracticality due to the exponential growth in features. Therefore, the **Polynomial Degree 2 Multinomial Logistic Regression** model offers robust and consistent performance, eliminating the need for more complex models like the polynomial degree **3** and **4** models. Now, we will build our **Custom Polynomial Degree 2 Multinomial Logistic Regression** model and compare the results with the scikit-learn optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "\n",
    "def polynomial_features_multiple(X: np.ndarray, degree: int):\n",
    "    \"\"\"\n",
    "    Generate polynomial features for a given standardized dataset X up to a specific degree.\n",
    "    \n",
    "    Parameters:\n",
    "    X (np.ndarray): The standardized input dataset of shape (n_samples, n_features).\n",
    "    degree (int): The degree of the polynomial features.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray: A new dataset with polynomial features of shape (n_samples, n_output_features).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    # List to hold the polynomial features\n",
    "    features = []\n",
    "    \n",
    "    # Add polynomial features of all degrees from 1 to the specified degree\n",
    "    for d in range(1, degree + 1):\n",
    "        for indices in combinations_with_replacement(range(n_features), d):\n",
    "            new_feature = np.prod(X[:, indices], axis=1)\n",
    "            features.append(new_feature)\n",
    "    \n",
    "    return np.vstack(features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100/1000: Cost 0.025256094558993584\n",
      "Iteration 200/1000: Cost 0.013207418209254789\n",
      "Iteration 300/1000: Cost 0.008968965239506051\n",
      "Iteration 400/1000: Cost 0.006803447193990029\n",
      "Iteration 500/1000: Cost 0.005487381298418004\n",
      "Iteration 600/1000: Cost 0.004602137894336613\n",
      "Iteration 700/1000: Cost 0.003965500216623285\n",
      "Iteration 800/1000: Cost 0.0034853852375776894\n",
      "Iteration 900/1000: Cost 0.0031102287784110626\n",
      "Iteration 1000/1000: Cost 0.0028088988398663564\n"
     ]
    }
   ],
   "source": [
    "# Train custom polynomial (degree 2) multinomial logistic regression model\n",
    "custom_poly2_mlr_model = MultinomialLogisticRegression(learning_rate=0.15)\n",
    "custom_poly2_mlr_model.fit(polynomial_features_multiple(X_train_scaled_, 2), y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Iteration=%{x}<br>Cost=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          100,
          200,
          300,
          400,
          500,
          600,
          700,
          800,
          900,
          1000
         ],
         "xaxis": "x",
         "y": [
          0.025256094558993584,
          0.013207418209254789,
          0.008968965239506051,
          0.006803447193990029,
          0.005487381298418004,
          0.004602137894336613,
          0.003965500216623285,
          0.0034853852375776894,
          0.0031102287784110626,
          0.0028088988398663564
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Iteration vs Cost"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Iteration"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Cost"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert cost history into numpy arrays\n",
    "cost_hist_ = np.array(custom_poly2_mlr_model.cost_history)\n",
    "\n",
    "# Plotly Express line chart\n",
    "fig = px.line(\n",
    "    x=cost_hist_[:, 0],\n",
    "    y=cost_hist_[:, 1],\n",
    "    title=\"Iteration vs Cost\",\n",
    "    labels={\"x\": \"Iteration\", \"y\": \"Cost\"}\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Saved as plot_2.png in the current directory/folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the decrease in cost as the number of iterations increases, indicating the proper functioning of gradient descent in minimizing cost and leading to optimal model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Polynomial (degree 2) Multinomial Logistic Regression:\n",
      "Training set - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000\n",
      "Validation set - Accuracy: 0.9858, Precision: 0.9862, Recall: 0.9858, F1-score: 0.9858\n",
      "Test set - Accuracy: 0.9902, Precision: 0.9903, Recall: 0.9902, F1-score: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the custom polynomial (degree 2) multinomial logistic regression model\n",
    "train_acc_, train_prec_, train_rec_, train_f1_ = \\\n",
    "        custom_poly2_mlr_model.evaluate_model(polynomial_features_multiple(X_train_scaled_, 2), y_train_)\n",
    "\n",
    "val_acc_, val_prec_, val_rec_, val_f1_ = \\\n",
    "        custom_poly2_mlr_model.evaluate_model(polynomial_features_multiple(X_val_scaled_, 2), y_val_)\n",
    "\n",
    "test_acc_, test_prec_, test_rec_, test_f1_ = \\\n",
    "        custom_poly2_mlr_model.evaluate_model(polynomial_features_multiple(X_test_scaled_, 2), y_test_)\n",
    "\n",
    "print(\"Custom Polynomial (degree 2) Multinomial Logistic Regression:\")\n",
    "\n",
    "print(f\"Training set - Accuracy: {train_acc_:.4f}, Precision: {train_prec_:.4f}, Recall: {train_rec_:.4f}, \"\n",
    "        f\"F1-score: {train_f1_:.4f}\")\n",
    "\n",
    "print(f\"Validation set - Accuracy: {val_acc_:.4f}, Precision: {val_prec_:.4f}, Recall: {val_rec_:.4f}, \"\n",
    "        f\"F1-score: {val_f1_:.4f}\")\n",
    "\n",
    "print(f\"Test set - Accuracy: {test_acc_:.4f}, Precision: {test_prec_:.4f}, Recall: {test_rec_:.4f}, \"\n",
    "        f\"F1-score: {test_f1_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn Polynomial (degree 2) Multinomial Logistic Regression: <br>\n",
    "Training set - Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-score: 1.0000 <br>\n",
    "Validation set - Accuracy: 0.9858, Precision: 0.9861, Recall: 0.9858, F1-score: 0.9858 <br>\n",
    "Test set - Accuracy: 0.9858, Precision: 0.9858, Recall: 0.9858, F1-score: 0.9858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Custom and Scikit-Learn implementations of the **Polynomial (degree 2) Multinomial Logistic Regression** model demonstrated excellent performance across the training, validation, and test sets. The Custom model achieved perfect scores on the training set (**accuracy**, **precision**, **recall**, and **F1-score** all at **1.0000**), with validation set metrics slightly lower but still high (**accuracy** 0.9858, **precision** 0.9862, **recall** and **F1-score** 0.9858), and test set metrics at (**accuracy** 0.9902, **precision** 0.9903, **recall** and **F1-score** 0.9902). Similarly, the Scikit-Learn model achieved perfect training set scores and comparable validation set results (**accuracy** 0.9858, **precision** 0.9861, **recall** and **F1-score** 0.9858), with the test set showing slightly lower metrics (all at **0.9858**). These results affirm the robustness and reliability of both implementations in predicting outcomes and generalizing to unseen data. So, with this comparison, our goal of building a **Multiclass Classification Model with Non-Linear Decision Boundaries** has been achieved successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
